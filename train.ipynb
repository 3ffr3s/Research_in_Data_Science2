{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('workspace/sy/sungyun/mdpi_IDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sy/sungyun/mdpi_IDS\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/sy/sungyun/mdpi_IDS',\n",
       " '/opt/conda/lib/python37.zip',\n",
       " '/opt/conda/lib/python3.7',\n",
       " '/opt/conda/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/conda/lib/python3.7/site-packages',\n",
       " '/opt/conda/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '../',\n",
       " 'workspace/sy/sungyun/mdpi_IDS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import PklsFolder, make_cls_idx, split_train_val_test\n",
    "from Layers import Flow_CLF\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_dataset = PklsFolder('../../pkls')  # ISCX 2012 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclasses = list(range(7))\\nclass_idx = make_cls_idx(flow_dataset.targets,classes,'./ISCX2012_null_index.npy')\\n\\ntrain_normal, val_normal, test_normal = split_train_val_test(class_idx[0],30000,15000,15000)\\ntrain_Infiltrating, val_Infiltrating, test_Infiltrating = split_train_val_test(class_idx[2],6000,2000,1900)\\ntrain_HttpDos, val_HttpDos,test_HttpDos = split_train_val_test(class_idx[3],2000,300,400)\\ntrain_DDos ,val_DDos,test_DDos = split_train_val_test(class_idx[4],10000,10000,10100)\\ntrain_BFSSH, val_BFSSH,test_BFSSH = split_train_val_test(class_idx[6],2000,2700,2600)\\n\\n\\ntrain_set_idx = train_normal+train_Infiltrating+train_HttpDos+train_DDos+train_BFSSH\\nval_set_idx = val_normal+val_Infiltrating+val_HttpDos+val_DDos+val_BFSSH\\ntest_set_idx = test_normal+test_Infiltrating+test_HttpDos+test_DDos+test_BFSSH\\n\\nnp.save('train_set_idx.npy', np.array(train_set_idx))\\nnp.save('val_set_idx.npy', np.array(val_set_idx))\\nnp.save('test_set_idx.npy', np.array(test_set_idx))\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classes = list(range(7))\n",
    "class_idx = make_cls_idx(flow_dataset.targets,classes,'./ISCX2012_null_index.npy')\n",
    "\n",
    "train_normal, val_normal, test_normal = split_train_val_test(class_idx[0],30000,15000,15000)\n",
    "train_Infiltrating, val_Infiltrating, test_Infiltrating = split_train_val_test(class_idx[2],6000,2000,1900)\n",
    "train_HttpDos, val_HttpDos,test_HttpDos = split_train_val_test(class_idx[3],2000,300,400)\n",
    "train_DDos ,val_DDos,test_DDos = split_train_val_test(class_idx[4],10000,10000,10100)\n",
    "train_BFSSH, val_BFSSH,test_BFSSH = split_train_val_test(class_idx[6],2000,2700,2600)\n",
    "\n",
    "\n",
    "train_set_idx = train_normal+train_Infiltrating+train_HttpDos+train_DDos+train_BFSSH\n",
    "val_set_idx = val_normal+val_Infiltrating+val_HttpDos+val_DDos+val_BFSSH\n",
    "test_set_idx = test_normal+test_Infiltrating+test_HttpDos+test_DDos+test_BFSSH\n",
    "\n",
    "np.save('train_set_idx.npy', np.array(train_set_idx))\n",
    "np.save('val_set_idx.npy', np.array(val_set_idx))\n",
    "np.save('test_set_idx.npy', np.array(test_set_idx))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2974196 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7316/2974196 [00:00<00:40, 73159.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 15518/2974196 [00:00<00:39, 75609.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 23970/2974196 [00:00<00:37, 78077.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 32649/2974196 [00:00<00:36, 80500.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 41282/2974196 [00:00<00:35, 82164.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 50016/2974196 [00:00<00:34, 83649.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 58800/2974196 [00:00<00:34, 84862.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 67569/2974196 [00:00<00:33, 85690.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 76458/2974196 [00:00<00:33, 86623.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 84843/2974196 [00:01<00:33, 85708.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 93222/2974196 [00:01<00:34, 84221.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 101516/2974196 [00:01<00:35, 80936.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 109547/2974196 [00:01<00:36, 78566.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 118314/2974196 [00:01<00:35, 81092.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 127226/2974196 [00:01<00:34, 83343.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 136091/2974196 [00:01<00:33, 84865.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 144973/2974196 [00:01<00:32, 86012.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 153909/2974196 [00:01<00:32, 86988.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 162622/2974196 [00:01<00:32, 86548.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 171627/2974196 [00:02<00:32, 87566.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 180578/2974196 [00:02<00:31, 88140.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 189400/2974196 [00:02<00:32, 85480.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 198244/2974196 [00:02<00:32, 86346.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 207334/2974196 [00:02<00:31, 87661.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 216396/2974196 [00:02<00:31, 88528.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 225420/2974196 [00:02<00:30, 89034.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 234415/2974196 [00:02<00:30, 89306.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 243594/2974196 [00:02<00:30, 90035.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 252605/2974196 [00:02<00:30, 88312.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 261692/2974196 [00:03<00:30, 89063.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 270797/2974196 [00:03<00:30, 89647.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 279770/2974196 [00:03<00:30, 89054.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 288682/2974196 [00:03<00:30, 88489.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 297537/2974196 [00:03<00:30, 87646.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 306308/2974196 [00:03<00:31, 85801.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 314901/2974196 [00:03<00:31, 85553.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 324043/2974196 [00:03<00:30, 87231.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 332781/2974196 [00:03<00:30, 86270.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 342185/2974196 [00:03<00:29, 88460.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 351054/2974196 [00:04<00:29, 88485.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 359919/2974196 [00:04<00:31, 83477.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 369559/2974196 [00:04<00:29, 86973.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 379311/2974196 [00:04<00:28, 89888.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 388688/2974196 [00:04<00:28, 91017.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 398011/2974196 [00:04<00:28, 91668.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 407247/2974196 [00:04<00:27, 91871.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 416466/2974196 [00:04<00:27, 91960.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 425769/2974196 [00:04<00:27, 92275.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 435103/2974196 [00:04<00:27, 92591.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 444452/2974196 [00:05<00:27, 92857.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 453838/2974196 [00:05<00:27, 93154.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 463263/2974196 [00:05<00:26, 93477.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 472770/2974196 [00:05<00:26, 93949.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 482223/2974196 [00:05<00:26, 94122.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 491787/2974196 [00:05<00:26, 94572.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 501247/2974196 [00:05<00:26, 94487.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 510704/2974196 [00:05<00:26, 94511.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 520371/2974196 [00:05<00:25, 95147.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 530197/2974196 [00:05<00:25, 96060.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 540139/2974196 [00:06<00:25, 97041.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 550036/2974196 [00:06<00:24, 97610.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 559802/2974196 [00:06<00:25, 96081.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 569419/2974196 [00:06<00:26, 90963.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 579202/2974196 [00:06<00:25, 92919.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 588548/2974196 [00:06<00:27, 87221.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 597380/2974196 [00:06<00:27, 85296.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 605996/2974196 [00:06<00:28, 84234.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 614483/2974196 [00:06<00:28, 83182.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 623225/2974196 [00:07<00:27, 84409.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 632479/2974196 [00:07<00:27, 86694.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 641711/2974196 [00:07<00:26, 88307.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 651029/2974196 [00:07<00:25, 89713.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 660296/2974196 [00:07<00:25, 90577.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 669386/2974196 [00:07<00:25, 90667.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 678470/2974196 [00:07<00:25, 90267.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 687509/2974196 [00:07<00:26, 86888.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 696234/2974196 [00:07<00:26, 85901.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 704852/2974196 [00:07<00:26, 85295.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 713991/2974196 [00:08<00:25, 87034.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 723224/2974196 [00:08<00:25, 88556.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 732417/2974196 [00:08<00:25, 89539.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 741602/2974196 [00:08<00:24, 90219.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 750639/2974196 [00:08<00:24, 89786.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 759770/2974196 [00:08<00:24, 90237.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 769049/2974196 [00:08<00:24, 90987.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 778155/2974196 [00:08<00:24, 88605.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 787268/2974196 [00:08<00:24, 89346.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 796863/2974196 [00:08<00:23, 91228.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 806075/2974196 [00:09<00:23, 91492.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 815239/2974196 [00:09<00:23, 91168.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 824366/2974196 [00:09<00:23, 91012.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 833509/2974196 [00:09<00:23, 91136.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 842682/2974196 [00:09<00:23, 91312.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 851823/2974196 [00:09<00:23, 91341.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 860960/2974196 [00:09<00:23, 91092.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 870072/2974196 [00:09<00:23, 89368.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 879018/2974196 [00:09<00:24, 86806.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 887840/2974196 [00:10<00:23, 87221.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 896795/2974196 [00:10<00:23, 87906.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 906564/2974196 [00:10<00:22, 90628.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 915792/2974196 [00:10<00:22, 91115.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 924926/2974196 [00:10<00:23, 88424.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 933801/2974196 [00:10<00:23, 86034.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 942722/2974196 [00:10<00:23, 86963.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 951867/2974196 [00:10<00:22, 88261.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 960718/2974196 [00:10<00:23, 86186.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 969412/2974196 [00:10<00:23, 86411.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 978170/2974196 [00:11<00:23, 86755.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 986860/2974196 [00:11<00:23, 84873.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 995367/2974196 [00:11<00:23, 83093.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 1003698/2974196 [00:11<00:23, 82132.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1012272/2974196 [00:11<00:23, 83181.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1021793/2974196 [00:11<00:22, 86458.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1030589/2974196 [00:11<00:22, 86902.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1039557/2974196 [00:11<00:22, 87716.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1048419/2974196 [00:11<00:21, 87980.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1057234/2974196 [00:11<00:22, 85586.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1066241/2974196 [00:12<00:21, 86882.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1075248/2974196 [00:12<00:21, 87813.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 1084305/2974196 [00:12<00:21, 88622.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1093182/2974196 [00:12<00:21, 86357.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1102409/2974196 [00:12<00:21, 88049.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1111634/2974196 [00:12<00:20, 89267.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1121073/2974196 [00:12<00:20, 90744.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1130169/2974196 [00:12<00:20, 90376.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1139657/2974196 [00:12<00:20, 91680.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1148840/2974196 [00:12<00:19, 91613.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1158012/2974196 [00:13<00:20, 87697.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1166825/2974196 [00:13<00:20, 87800.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1175636/2974196 [00:13<00:21, 84905.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1184194/2974196 [00:13<00:21, 85103.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1192737/2974196 [00:13<00:20, 85200.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1201739/2974196 [00:13<00:20, 86589.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1210746/2974196 [00:13<00:20, 87603.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1219837/2974196 [00:13<00:19, 88569.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 1228857/2974196 [00:13<00:19, 89049.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1237773/2974196 [00:13<00:19, 88859.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1246896/2974196 [00:14<00:19, 89555.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1255859/2974196 [00:14<00:19, 89441.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1264808/2974196 [00:14<00:19, 87256.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1273980/2974196 [00:14<00:19, 88548.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1283269/2974196 [00:14<00:18, 89805.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1292265/2974196 [00:14<00:18, 89762.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1301344/2974196 [00:14<00:18, 90065.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1310363/2974196 [00:14<00:18, 90100.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1319698/2974196 [00:14<00:18, 91050.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1328810/2974196 [00:15<00:18, 90688.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1338491/2974196 [00:15<00:17, 92441.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1348314/2974196 [00:15<00:17, 94104.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1357740/2974196 [00:15<00:17, 92914.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1367597/2974196 [00:15<00:16, 94540.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1377737/2974196 [00:15<00:16, 96498.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1387841/2974196 [00:15<00:16, 97815.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1397774/2974196 [00:15<00:16, 98263.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1407697/2974196 [00:15<00:15, 98551.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1417642/2974196 [00:15<00:15, 98817.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1427601/2974196 [00:16<00:15, 99047.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1437511/2974196 [00:16<00:15, 98940.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 1447451/2974196 [00:16<00:15, 99076.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1457422/2974196 [00:16<00:15, 99263.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1467351/2974196 [00:16<00:15, 96881.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1477075/2974196 [00:16<00:15, 96986.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1486784/2974196 [00:16<00:15, 94619.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 1496613/2974196 [00:16<00:15, 95688.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 1506199/2974196 [00:16<00:15, 92875.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 1515517/2974196 [00:16<00:16, 91068.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 1524653/2974196 [00:17<00:16, 87662.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 1533646/2974196 [00:17<00:16, 88329.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 1542640/2974196 [00:17<00:16, 88804.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 1551546/2974196 [00:17<00:16, 87710.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 1560338/2974196 [00:17<00:16, 87407.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 1569094/2974196 [00:17<00:16, 86883.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 1578194/2974196 [00:17<00:15, 88075.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 1587014/2974196 [00:17<00:16, 82992.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 1595881/2974196 [00:17<00:16, 84616.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 1604955/2974196 [00:17<00:15, 86363.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 1613991/2974196 [00:18<00:15, 87524.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 1623130/2974196 [00:18<00:15, 88646.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 1632212/2974196 [00:18<00:15, 89287.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 1641163/2974196 [00:18<00:15, 87026.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 1650336/2974196 [00:18<00:14, 88384.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 1659200/2974196 [00:18<00:14, 87939.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 1668012/2974196 [00:18<00:14, 87905.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 1677092/2974196 [00:18<00:14, 88751.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 1686258/2974196 [00:18<00:14, 89601.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 1695527/2974196 [00:19<00:14, 90504.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 1704832/2974196 [00:19<00:13, 91251.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 1714096/2974196 [00:19<00:13, 91662.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 1723308/2974196 [00:19<00:13, 91797.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 1732492/2974196 [00:19<00:13, 91309.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 1741627/2974196 [00:19<00:13, 89788.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 1750614/2974196 [00:19<00:13, 87753.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 1759457/2974196 [00:19<00:13, 87954.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 1768864/2974196 [00:19<00:13, 89701.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 1778028/2974196 [00:19<00:13, 90273.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 1787068/2974196 [00:20<00:13, 90253.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 1796213/2974196 [00:20<00:13, 90603.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 1805442/2974196 [00:20<00:12, 91100.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 1814558/2974196 [00:20<00:12, 89906.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 1823556/2974196 [00:20<00:12, 89363.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1832985/2974196 [00:20<00:12, 90784.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1842479/2974196 [00:20<00:12, 91989.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1851975/2974196 [00:20<00:12, 92859.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1861271/2974196 [00:20<00:12, 91060.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1870392/2974196 [00:20<00:12, 89036.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1879889/2974196 [00:21<00:12, 90735.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 1889154/2974196 [00:21<00:11, 91299.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1898301/2974196 [00:21<00:12, 87229.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1907316/2974196 [00:21<00:12, 88083.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 1916162/2974196 [00:21<00:12, 84877.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 1925266/2974196 [00:21<00:12, 86636.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 1934363/2974196 [00:21<00:11, 87890.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 1943497/2974196 [00:21<00:11, 88895.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 1952589/2974196 [00:21<00:11, 89492.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 1961599/2974196 [00:21<00:11, 89670.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 1970581/2974196 [00:22<00:11, 89341.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1979526/2974196 [00:22<00:11, 89098.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1988444/2974196 [00:22<00:11, 88911.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1997341/2974196 [00:22<00:11, 88271.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 2006297/2974196 [00:22<00:10, 88654.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 2015167/2974196 [00:22<00:10, 87748.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 2024108/2974196 [00:22<00:10, 88238.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 2033856/2974196 [00:22<00:10, 90819.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 2042960/2974196 [00:22<00:10, 89388.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 2052703/2974196 [00:22<00:10, 91657.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 2062292/2974196 [00:23<00:09, 92886.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 2072045/2974196 [00:23<00:09, 94231.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 2081784/2974196 [00:23<00:09, 95155.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 2091553/2974196 [00:23<00:09, 95899.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 2101393/2974196 [00:23<00:09, 96634.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 2111184/2974196 [00:23<00:08, 97013.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 2120894/2974196 [00:23<00:08, 96997.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 2130600/2974196 [00:23<00:08, 94129.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 2140660/2974196 [00:23<00:08, 95980.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 2150283/2974196 [00:24<00:08, 93622.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 2159676/2974196 [00:24<00:08, 91208.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 2168832/2974196 [00:24<00:08, 91195.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 2177976/2974196 [00:24<00:08, 88684.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 2187819/2974196 [00:24<00:08, 91398.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 2197768/2974196 [00:24<00:08, 93683.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 2207665/2974196 [00:24<00:08, 95207.62it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2217329/2974196 [00:24<00:07, 95631.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 2226919/2974196 [00:24<00:08, 92202.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 2236185/2974196 [00:24<00:08, 90927.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 2245517/2974196 [00:25<00:07, 91631.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 2254707/2974196 [00:25<00:07, 90679.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 2263796/2974196 [00:25<00:07, 90037.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 2272891/2974196 [00:25<00:07, 90306.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 2281960/2974196 [00:25<00:07, 90420.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 2291010/2974196 [00:25<00:07, 90265.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 2300044/2974196 [00:25<00:07, 90284.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 2309077/2974196 [00:25<00:07, 89768.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 2318058/2974196 [00:25<00:07, 88633.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 2326927/2974196 [00:25<00:07, 87652.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 2335699/2974196 [00:26<00:07, 87466.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 2344588/2974196 [00:26<00:07, 87887.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 2353381/2974196 [00:26<00:07, 86332.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 2362335/2974196 [00:26<00:07, 87269.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 2371390/2974196 [00:26<00:06, 88226.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 2380247/2974196 [00:26<00:06, 88326.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 2389086/2974196 [00:26<00:06, 88170.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 2397908/2974196 [00:26<00:06, 87419.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 2406655/2974196 [00:26<00:06, 86652.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 2415325/2974196 [00:26<00:06, 86495.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 2424687/2974196 [00:27<00:06, 88514.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 2434349/2974196 [00:27<00:05, 90799.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 2444133/2974196 [00:27<00:05, 92801.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 2454009/2974196 [00:27<00:05, 94512.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 2464003/2974196 [00:27<00:05, 96075.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 2473855/2974196 [00:27<00:05, 96793.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 2483554/2974196 [00:27<00:05, 94768.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 2493054/2974196 [00:27<00:05, 88713.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 2503021/2974196 [00:27<00:05, 91737.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 2512848/2974196 [00:28<00:04, 93602.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 2522283/2974196 [00:28<00:04, 92716.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 2531609/2974196 [00:28<00:04, 91980.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 2540846/2974196 [00:28<00:04, 91308.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 2550021/2974196 [00:28<00:04, 91439.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 2559185/2974196 [00:28<00:04, 88942.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 2568348/2974196 [00:28<00:04, 89730.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 2577569/2974196 [00:28<00:04, 90458.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 2586632/2974196 [00:28<00:04, 87907.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 2595551/2974196 [00:28<00:04, 88287.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 2604483/2974196 [00:29<00:04, 88593.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 2613357/2974196 [00:29<00:04, 88307.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 2622198/2974196 [00:29<00:03, 88011.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 2631044/2974196 [00:29<00:03, 88145.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 2639912/2974196 [00:29<00:03, 88302.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 2648746/2974196 [00:29<00:03, 88133.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 2657595/2974196 [00:29<00:03, 88239.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 2666421/2974196 [00:29<00:03, 88188.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 2675439/2974196 [00:29<00:03, 88774.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 2684319/2974196 [00:29<00:03, 88211.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 2693193/2974196 [00:30<00:03, 88369.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 2702092/2974196 [00:30<00:03, 88554.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 2711090/2974196 [00:30<00:02, 88974.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 2719989/2974196 [00:30<00:02, 88792.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 2729001/2974196 [00:30<00:02, 89183.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 2737921/2974196 [00:30<00:02, 89050.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 2747318/2974196 [00:30<00:02, 90469.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 2756901/2974196 [00:30<00:02, 92012.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 2766250/2974196 [00:30<00:02, 92450.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 2775650/2974196 [00:30<00:02, 92906.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 2785156/2974196 [00:31<00:02, 93542.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 2794516/2974196 [00:31<00:01, 91110.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 2803645/2974196 [00:31<00:01, 89076.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 2812657/2974196 [00:31<00:01, 89386.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 2821612/2974196 [00:31<00:01, 87783.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 2830408/2974196 [00:31<00:01, 86283.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 2839065/2974196 [00:31<00:01, 86368.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 2847803/2974196 [00:31<00:01, 86669.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 2856523/2974196 [00:31<00:01, 86827.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 2865213/2974196 [00:31<00:01, 85748.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 2873796/2974196 [00:32<00:01, 85000.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 2882303/2974196 [00:32<00:01, 83957.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 2890707/2974196 [00:32<00:01, 83055.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 2899302/2974196 [00:32<00:00, 83902.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 2907700/2974196 [00:32<00:00, 83521.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 2916058/2974196 [00:32<00:00, 81555.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 2924857/2974196 [00:32<00:00, 83383.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 2933216/2974196 [00:32<00:00, 61489.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 2940211/2974196 [00:33<00:00, 42353.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 2945844/2974196 [00:33<00:00, 36689.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 2950626/2974196 [00:33<00:00, 32749.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 2954759/2974196 [00:33<00:00, 31593.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 2958528/2974196 [00:33<00:00, 29243.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 2961914/2974196 [00:34<00:00, 25818.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 2964893/2974196 [00:34<00:00, 25455.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 2967718/2974196 [00:34<00:00, 18383.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 2970030/2974196 [00:34<00:00, 15191.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 2971973/2974196 [00:34<00:00, 15143.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 2974196/2974196 [00:34<00:00, 85176.13it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "mal_cnt = 0\n",
    "over_flow_80 = 0\n",
    "over_packet_350 = 0\n",
    "total_packet_cnt = 0\n",
    "\n",
    "for i in tqdm(range(len(flow_dataset))):\n",
    "    flow, label = flow_dataset[i]\n",
    "    \n",
    "    if label != 0 :\n",
    "        mal_cnt +=1\n",
    "        if len(flow) > 80:\n",
    "            over_flow_80 += 1\n",
    "            \n",
    "        for j in range(len(flow)):\n",
    "            total_packet_cnt += 1\n",
    "            if len(flow[j]) > 350:\n",
    "                over_packet_350 +=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.72313520960441"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_len / mal_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.42022023278962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet_len / flow_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22708784360034115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_flow_80/ mal_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04307689185559776"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_packet_350 / total_packet_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_idx = np.load('train_set_idx.npy')\n",
    "train_random_sampler = torch.utils.data.SubsetRandomSampler(train_set_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = 32\n",
    "num_epoch = 20\n",
    "\n",
    "num_layers = 2 # Byte_EncoderLayer 개수\n",
    "d_model = 40\n",
    "num_heads = 4\n",
    "d_k = 10\n",
    "d_v = 10\n",
    "d_hid = (d_model * 2) #PositionwiseFeedForward hidden dim\n",
    "add_attn_dim = (d_model * 2) # PacketEncoder attn_dim\n",
    "pck_len = flow_dataset[0][0].shape[1]\n",
    "num_classes = 2\n",
    "dropout = 0.1\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cuda:7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(flow_dataset, batch_size = batch_size, shuffle = False,  sampler = train_random_sampler)\n",
    "#model = Flow_CLF(num_layers, d_model,num_heads, d_k, d_v, d_hid, add_attn_dim, pck_len, device, num_classes = num_classes, dropout = dropout).to(device)\n",
    "model = Flow_CLF(num_layers, d_model,num_heads, d_k, d_v, d_hid, add_attn_dim, pck_len, device, num_classes = num_classes, dropout = dropout).to('cuda:7')\n",
    "model = torch.nn.DataParallel(model, device_ids = [7,0,1,2,3,4,5,6], output_device = 7)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]/workspace/sy/sungyun/mdpi_IDS/Layers.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_score = self.softmax(attn2).unsqueeze(-1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 1 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 182, in forward\n    score, byte_encoding = self.ByteEncoder(flow)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 151, in forward\n    score, output = layer(output)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 139, in forward\n    score, output = self.MultiHeadAttention(input,mask = mask)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 63, in forward\n    score, context = self.ScaledDotProductAttention(WQ,WK,WV, mask)  #context shape : (batch_size, num_heads, seq_len, d_v)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 25, in forward\n    output = torch.matmul(score,v)\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 3.43 GiB already allocated; 38.56 MiB free; 3.54 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5c3a4b77f262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 1 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 182, in forward\n    score, byte_encoding = self.ByteEncoder(flow)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 151, in forward\n    score, output = layer(output)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 139, in forward\n    score, output = self.MultiHeadAttention(input,mask = mask)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 63, in forward\n    score, context = self.ScaledDotProductAttention(WQ,WK,WV, mask)  #context shape : (batch_size, num_heads, seq_len, d_v)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/workspace/sy/sungyun/mdpi_IDS/Layers.py\", line 25, in forward\n    output = torch.matmul(score,v)\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 3.43 GiB already allocated; 38.56 MiB free; 3.54 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "best= {'loss' : sys.float_info.max}\n",
    "attn_model_save_path = './model'\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_id, (train_x, train_y) in enumerate(tqdm(train_dataloader)):  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(train_x.type(torch.long).to(device))\n",
    "        loss = criterion(preds, train_y.type(torch.long).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if (batch_id+1) % 100 == 0:\n",
    "            print(f' iter : {batch_id+1} avg_loss : {epoch_loss/(batch_id+1)}')\n",
    "            print(f' iter : {batch_id+1} accuracy : {((preds.argmax(dim=1) == train_y.type(torch.long).to(device)).sum().item())/batch_size}')\n",
    "    loss_history.append(epoch_loss)\n",
    "    if epoch_loss < best['loss']:\n",
    "        best['state'] = model.state_dict()\n",
    "        best['loss'] = epoch_loss\n",
    "        best['epoch'] = epoch\n",
    "\n",
    "    print(f'epoch : {epoch}, total train loss : {epoch_loss}') \n",
    "    with open(f'{attn_model_save_path}model_epoch_{epoch+1}.pt','wb') as f:\n",
    "        torch.save({\n",
    "            'state' : model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'epoch' : epoch,\n",
    "            'loss_history' : loss_history,\n",
    "            'best_loss' : best['loss']\n",
    "        },f)\n",
    "\n",
    "with open(f'{attn_model_save_path}/best_model.pt', 'wb') as f:\n",
    "    torch.save(\n",
    "    {\n",
    "        'state' : best['state'],\n",
    "        'best_epoch' : best['epoch'],\n",
    "        'loss_history' : loss_history\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-ef2b92eb85af>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-ef2b92eb85af>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    nn.embedding 부분 그냥 word2vec으로 바꿀까\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nn.embedding 부분 그냥 word2vec으로 바꿀까\n",
    "Pkls_Folder에서 flow 길이/packet 길이 패딩 부분 수정해야 됨 + Flow_CLF에서 pck_len 인자 값 바꿔주기\n",
    "\n",
    "데이터 전처리 : [] 빈 데이터 삭제하고 flow 구성하는 패킷 개수, 각 패킷의 크기 등 정하기\n",
    "\n",
    "dropout 사용하기 때문에 \n",
    "model.train()\n",
    "model.eval()  이 코드 꼭 넣기\n",
    "\n",
    "논문에서 3.4 Embedding and Softmax 부분 다시 보기\n",
    "-embedding layer ouput을 루트 d_model로 나눠야 되는건지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
