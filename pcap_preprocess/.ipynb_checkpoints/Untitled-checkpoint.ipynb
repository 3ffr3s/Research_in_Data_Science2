{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import scapy.all\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(target):\n",
    "    return pd.read_csv(target,encoding='cp1252').rename(columns=lambda x: x.strip()).dropna(subset=['Flow ID'], how='all')\n",
    "\n",
    "def dataframe_from_csvs(targets):\n",
    "    return pd.concat([dataframe_from_csv(x) for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thu_pcap_dir = '../../../dataset/CICIDS2017/split_pcaps/Thu'\n",
    "Thu_pcap_files = sorted([x for x in Path(Thu_pcap_dir).glob('*.pcap')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 41707/485320 [00:00<00:02, 203812.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-15_49474.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-15_49910.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-0-65_443_192-168-10-15_55091.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-128-65_443_192-168-10-15_55094.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-192-65_443_192-168-10-15_55096.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-192-65_443_192-168-10-15_55126.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_165-254-0-106_80_192-168-10-15_52424.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_172-217-7-14_443_192-168-10-25_51310.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 99407/485320 [00:00<00:01, 197681.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-15_49910_13-107-4-50_80.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 279095/485320 [00:01<00:01, 203005.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-15-4-9_80_192-168-10-15_59707.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-8_49636.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-8_53987.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-9_5708.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-250-135-254_80_192-168-10-15_50054.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-253-104-46_80_192-168-10-15_59694.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-253-104-46_80_192-168-10-15_59697.pcap\n",
      "../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_91-189-88-161_80_192-168-10-50_40106.pcap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485320/485320 [00:02<00:00, 198057.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from os.path import getsize\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in tqdm(range(len(Thu_pcap_files))):\n",
    "    if getsize(Thu_pcap_files[i]) > 20000000 :\n",
    "        print(Thu_pcap_files[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz = sorted(test, key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-15_49910.pcap'), 3166498201)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_165-254-0-106_80_192-168-10-15_52424.pcap'), 639599731)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-192-65_443_192-168-10-15_55126.pcap'), 329203512)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-128-65_443_192-168-10-15_55094.pcap'), 94163671)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-15_49910_13-107-4-50_80.pcap'), 80149199)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-192-65_443_192-168-10-15_55096.pcap'), 73925090)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_172-217-7-14_443_192-168-10-25_51310.pcap'), 67239943)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-250-135-254_80_192-168-10-15_50054.pcap'), 54349630)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_91-189-88-161_80_192-168-10-50_40106.pcap'), 53611231)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-0-65_443_192-168-10-15_55091.pcap'), 48038474)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-8_53987.pcap'), 28249403)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-8_49636.pcap'), 28235175)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_45-33-49-119_443_192-168-10-9_5708.pcap'), 28229723)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-253-104-46_80_192-168-10-15_59694.pcap'), 24419404)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-15-4-9_80_192-168-10-15_59707.pcap'), 22120572)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-253-104-46_80_192-168-10-15_59697.pcap'), 21588243)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-15_49474.pcap'), 20632163)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-25_51325_205-174-165-73_444.pcap'), 13706814)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_66-102-255-37_443_192-168-10-5_57670.pcap'), 12773223)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-15_52424_165-254-0-106_80.pcap'), 11870641)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-15-4-18_80_192-168-10-5_49290.pcap'), 11069913)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-192-65_443_192-168-10-15_55166.pcap'), 11052557)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_208-185-118-99_80_192-168-10-15_50222.pcap'), 11027597)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_52-84-26-56_443_192-168-10-9_3256.pcap'), 10640488)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_209-48-71-154_80_192-168-10-8_49229.pcap'), 10278721)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-15-4-18_80_192-168-10-8_49669.pcap'), 10202468)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-219-231-193_443_192-168-10-14_64468.pcap'), 10172130)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_104-16-39-35_443_192-168-10-15_60315.pcap'), 9926627)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-8_54119_205-174-165-73_444.pcap'), 9810070)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_54-192-48-130_443_192-168-10-9_7642.pcap'), 9590422)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-15_49452.pcap'), 9354040)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_49389.pcap'), 9329614)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_13-107-4-50_80_192-168-10-3_59022.pcap'), 9306317)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_54-192-48-130_443_192-168-10-9_7641.pcap'), 9291501)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-168-10-15_55126_151-101-192-65_443.pcap'), 9091368)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_52-84-26-206_443_192-168-10-5_51048.pcap'), 8883125)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_49387.pcap'), 8829496)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_49388.pcap'), 8732104)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_104-16-162-179_443_192-168-10-17_55531.pcap'), 8672368)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_207-229-75-26_443_192-168-10-17_57559.pcap'), 8227655)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_50280.pcap'), 8172317)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-62-239-8_80_192-168-10-5_57963.pcap'), 7904691)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-0-72-24_443_192-168-10-9_5391.pcap'), 7835423)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_50304.pcap'), 6999837)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_49843.pcap'), 6967029)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_151-101-210-2_80_192-168-10-14_61100.pcap'), 6903406)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-1-139-139_443_192-168-10-25_51017.pcap'), 6849215)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_192-229-210-12_80_192-168-10-14_49386.pcap'), 6748958)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_23-15-4-8_443_192-168-10-15_52794.pcap'), 6669347)\n",
      "(PosixPath('../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_184-31-202-156_443_192-168-10-25_51162.pcap'), 6606350)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(plz[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkcs = scapy.sendrecv.sniff(offline = '../../../dataset/CICIDS2017/split_pcaps/Thu/Thursday-WorkingHours.pcap.TCP_8-250-135-254_80_192-168-10-15_50054.pcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sniffed: TCP:20495 UDP:0 ICMP:0 Other:0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9534900\n",
      "drwxr-xr-x 2 root root   57360384 Nov 15 21:51 .\n",
      "drwxr-xr-x 4 root root       4096 Nov 15 21:49 ..\n",
      "-rw-r--r-- 1 root root       4385 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57627.pcap\n",
      "-rw-r--r-- 1 root root       1363 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57628.pcap\n",
      "-rw-r--r-- 1 root root       1253 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57629.pcap\n",
      "-rw-r--r-- 1 root root       1202 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57630.pcap\n",
      "-rw-r--r-- 1 root root       1393 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57631.pcap\n",
      "-rw-r--r-- 1 root root       1064 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57632.pcap\n",
      "-rw-r--r-- 1 root root       1032 Nov 15 21:50 Thursday-WorkingHours.pcap.TCP_1-1-70-73_80_192-168-10-19_57642.pcap\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls -al ../../../dataset/CICIDS2017/split_pcaps/Thu/ | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DtypeWarning: Columns (0,1,3,6,84) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "Thursday_csv= sorted([x for x in Path('../../../dataset/CICIDS2017/flow_label/TrafficLabelling').glob('Thursday-*.csv')],reverse = True)\n",
    "# Morning - Afternoon 순서로 정리하기 위해서\n",
    "\n",
    "Thursday_DF_RAW = dataframe_from_csvs(Thursday_csv)\n",
    "Thursday_DF = Thursday_DF_RAW.drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first')\n",
    "\n",
    "Thursday_Benign_DF = Thursday_DF[Thursday_DF['Label'] == 'BENIGN']\n",
    "Thursday_Mal_DF = Thursday_DF[Thursday_DF['Label'] != 'BENIGN']\n",
    "# (1분 단위로 동일한 flow를 서로 다른 flow로 분류해놓아서) 5-tuple이 같으면 동일한 flow로 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tup_pcap(df, pcap_dir):\n",
    "    sip,sport,dip,dport,protocol = df[['Source IP','Source Port','Destination IP','Destination Port','Protocol']]\n",
    "    protocol = 'TCP' if int(protocol) ==6 else 'UDP' if int(protocol) ==17 else 'HOPOPT'\n",
    "    \n",
    "    if protocol == 'HOPOPT':\n",
    "        return False        \n",
    "    elif protocol == 'TCP' or five_tup[4] == 'UDP':\n",
    "        week = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "        file_path = pcap_dir + '/' + [day for day in week if pcap_dir[-3:] in day][0] +'-WorkingHours.pcap.'+protocol+'_'+sip.replace('.','-')+'_'+ str(int(sport))+'_'+dip.replace('.','-')+'_'+str(int(dport))+'.pcap'\n",
    "        return scapy.sendrecv.sniff(offline = file_path)\n",
    "    else :\n",
    "        print('Non-Exist Protocol')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ben_mal_DF(Day_DF):\n",
    "    fwd_Benign_DF = Day_DF[Day_DF['Label'] == 'BENIGN'][['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Benign_DF = Day_DF[Day_DF['Label'] == 'BENIGN'][['Destination IP', 'Destination Port','Source IP', 'Source Port',  'Protocol','Label','Timestamp']]\n",
    "    bwd_Benign_DF.columns = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']\n",
    "    Benign_DF = pd.concat([fwd_Benign_DF, bwd_Benign_DF]).drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first').reset_index(drop = True)\n",
    "    \n",
    "    fwd_Mal_DF = Day_DF[Day_DF['Label'] != 'BENIGN'][['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Mal_DF = Day_DF[Day_DF['Label'] != 'BENIGN'][['Destination IP', 'Destination Port','Source IP', 'Source Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Mal_DF.columns = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']\n",
    "    Mal_DF = pd.concat([fwd_Mal_DF,bwd_Mal_DF]).drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "    return Benign_DF, Mal_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_dup_btw_df(df1, df2):\n",
    "    tmp = pd.concat([df1,df2]).reset_index(drop = True)\n",
    "    dup_index = tmp[tmp.duplicated(subset = ['Source IP','Source Port','Destination IP', 'Destination Port', 'Protocol'], keep = 'last')].index\n",
    "    dup_index = dup_index[dup_index < len(df1)]\n",
    "    return df1.drop(index = dup_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Benign_DF, Mal_DF = split_ben_mal_DF(Thursday_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_Benign_DF = del_dup_btw_df(Benign_DF, Mal_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mal_dup_list = Mal_DF.duplicated(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol'],keep = False)    \n",
    "pure_Mal_DF = Mal_DF[~Mal_dup_list]\n",
    "dup_Mal_DF = Mal_DF[Mal_dup_list]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([pure_Benign_DF,pure_Mal_DF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Source IP, Source Port, Destination IP, Destination Port, Protocol, Label, Timestamp]\n",
       "Index: []"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.duplicated(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = pd.concat([pure_Benign_DF, Mal_DF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>52776.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54268.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54956.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59300.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59786.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>52776.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54268.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54956.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59786.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source IP  Source Port Destination IP  Destination Port  Protocol  \\\n",
       "1393     172.16.0.1      52776.0  192.168.10.50              80.0       6.0   \n",
       "1467     172.16.0.1      54268.0  192.168.10.50              80.0       6.0   \n",
       "1540     172.16.0.1      54956.0  192.168.10.50              80.0       6.0   \n",
       "1728     172.16.0.1      59300.0  192.168.10.50              80.0       6.0   \n",
       "1753     172.16.0.1      59786.0  192.168.10.50              80.0       6.0   \n",
       "1961     172.16.0.1      34940.0  192.168.10.50              80.0       6.0   \n",
       "3405  192.168.10.50         80.0     172.16.0.1           52776.0       6.0   \n",
       "3479  192.168.10.50         80.0     172.16.0.1           54268.0       6.0   \n",
       "3552  192.168.10.50         80.0     172.16.0.1           54956.0       6.0   \n",
       "3740  192.168.10.50         80.0     172.16.0.1           59300.0       6.0   \n",
       "3765  192.168.10.50         80.0     172.16.0.1           59786.0       6.0   \n",
       "3973  192.168.10.50         80.0     172.16.0.1           34940.0       6.0   \n",
       "\n",
       "                 Label       Timestamp  \n",
       "1393  Web Attack – XSS  6/7/2017 10:17  \n",
       "1467  Web Attack – XSS  6/7/2017 10:19  \n",
       "1540  Web Attack – XSS  6/7/2017 10:21  \n",
       "1728  Web Attack – XSS  6/7/2017 10:27  \n",
       "1753  Web Attack – XSS  6/7/2017 10:28  \n",
       "1961  Web Attack – XSS  6/7/2017 10:34  \n",
       "3405  Web Attack – XSS  6/7/2017 10:17  \n",
       "3479  Web Attack – XSS  6/7/2017 10:19  \n",
       "3552  Web Attack – XSS  6/7/2017 10:21  \n",
       "3740  Web Attack – XSS  6/7/2017 10:27  \n",
       "3765  Web Attack – XSS  6/7/2017 10:28  \n",
       "3973  Web Attack – XSS  6/7/2017 10:34  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver[ver.duplicated(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>52776.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54268.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54956.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59300.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59786.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>52776.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54268.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54956.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>59786.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source IP  Source Port Destination IP  Destination Port  Protocol  \\\n",
       "1393     172.16.0.1      52776.0  192.168.10.50              80.0       6.0   \n",
       "1467     172.16.0.1      54268.0  192.168.10.50              80.0       6.0   \n",
       "1540     172.16.0.1      54956.0  192.168.10.50              80.0       6.0   \n",
       "1728     172.16.0.1      59300.0  192.168.10.50              80.0       6.0   \n",
       "1753     172.16.0.1      59786.0  192.168.10.50              80.0       6.0   \n",
       "1961     172.16.0.1      34940.0  192.168.10.50              80.0       6.0   \n",
       "3405  192.168.10.50         80.0     172.16.0.1           52776.0       6.0   \n",
       "3479  192.168.10.50         80.0     172.16.0.1           54268.0       6.0   \n",
       "3552  192.168.10.50         80.0     172.16.0.1           54956.0       6.0   \n",
       "3740  192.168.10.50         80.0     172.16.0.1           59300.0       6.0   \n",
       "3765  192.168.10.50         80.0     172.16.0.1           59786.0       6.0   \n",
       "3973  192.168.10.50         80.0     172.16.0.1           34940.0       6.0   \n",
       "\n",
       "                 Label       Timestamp  \n",
       "1393  Web Attack – XSS  6/7/2017 10:17  \n",
       "1467  Web Attack – XSS  6/7/2017 10:19  \n",
       "1540  Web Attack – XSS  6/7/2017 10:21  \n",
       "1728  Web Attack – XSS  6/7/2017 10:27  \n",
       "1753  Web Attack – XSS  6/7/2017 10:28  \n",
       "1961  Web Attack – XSS  6/7/2017 10:34  \n",
       "3405  Web Attack – XSS  6/7/2017 10:17  \n",
       "3479  Web Attack – XSS  6/7/2017 10:19  \n",
       "3552  Web Attack – XSS  6/7/2017 10:21  \n",
       "3740  Web Attack – XSS  6/7/2017 10:27  \n",
       "3765  Web Attack – XSS  6/7/2017 10:28  \n",
       "3973  Web Attack – XSS  6/7/2017 10:34  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_DF[Mal_DF.duplicated(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 7, 6, 8, 59)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(Benign_DF.iloc[0]['Timestamp'],'%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowSaver:\n",
    "    def __init__(self, folder_capacity, flow_class, pkls_dir):\n",
    "        self.folder_capacity = folder_capacity\n",
    "        self.flow_class = flow_class\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class))).mkdir(parents=True, exist_ok=True)\n",
    "        self.pkls_dir = pkls_dir\n",
    "        self.index = 0\n",
    "        self.num = 0\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class), str(self.index))).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def save_flow(self, flow_array):\n",
    "        if self.num==self.folder_capacity:\n",
    "            self.new_folder()\n",
    "        pkl_path = os.path.join(pkls_dir, str(self.flow_class), str(self.index), f'{self.flow_class}_{self.index}{self.num:04d}.pkl')\n",
    "        with open(pkl_path, 'wb') as f:\n",
    "            pickle.dump(flow_array, f)\n",
    "        self.num+=1\n",
    "    \n",
    "    def new_folder(self):\n",
    "        self.index+=1\n",
    "        self.num = 0\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class), str(self.index))).mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class FlowSaver:\n",
    "    def __init__(self, folder_capacity, flow_class, pkls_dir):\n",
    "        self.folder_capacity = folder_capacity\n",
    "        self.flow_class = flow_class\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class))).mkdir(parents=True, exist_ok=True)\n",
    "        self.pkls_dir = pkls_dir\n",
    "        self.index = 0\n",
    "        self.num = 0\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class), str(self.index))).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def save_flow(self, df, pcap_dir):\n",
    "        for df_idx in tqdm(range(len(df))):\n",
    "            five_tup = df.iloc[df_idx][['Source IP','Source Port','Destination IP','Destination Port','Protocol']]\n",
    "            five_tup[4] = 'TCP' if int(five_tup[4]) ==6 else 'UDP' if int(five_tup[4]) ==17 else 'HOPOPT'\n",
    "            \n",
    "            label = df.iloc[df_idx]['Label']\n",
    "            timestamp = datetime.strptime(df.iloc[df_idx]['Timestamp'],'%d/%m/%Y %H:%M')\n",
    "            #timestamp = datetime.strptime(df.iloc[i]['Timestamp'],'%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "            if five_tup[4] == 'HOPOPT':\n",
    "                continue\n",
    "            elif five_tup[4] == 'TCP' or five_tup[4] == 'UDP':\n",
    "                flow_array = []\n",
    "                pcks = self._find_tup_pcap(pcap_dir, five_tup) \n",
    "                #flow : 하루 동안의 5tup이 같은 패킷들을 하나의 flow로 정의\n",
    "                \n",
    "                for i in range(len(pcks)):\n",
    "                    flow_array.append(bytes(pcks[i]))\n",
    "                \n",
    "                if self.num==self.folder_capacity:\n",
    "                    self.new_folder()\n",
    "                pkl_path = os.path.join(pkls_dir, str(self.flow_class), str(self.index), f'{self.flow_class}_{self.index}{self.num:04d}.pkl')\n",
    "                with open(pkl_path, 'wb') as f:\n",
    "                    pickle.dump(flow_array, f)\n",
    "                self.num+=1\n",
    "            else:\n",
    "                print('Non-Exist Protocol')\n",
    "\n",
    "\n",
    "    def new_folder(self):\n",
    "        self.index+=1\n",
    "        self.num = 0\n",
    "        Path(os.path.join(pkls_dir, str(self.flow_class), str(self.index))).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _find_tup_pcap(self,split_pcap_dir, five_tup):\n",
    "        sip,sport,dip,dport,protocol = five_tup\n",
    "        week = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "        file_path = split_pcap_dir + '/' + [day for day in week if split_pcap_dir[-3:] in day][0] +'-WorkingHours.pcap.'+protocol+'_'+sip.replace('.','-')+'_'+ str(int(sport))+'_'+dip.replace('.','-')+'_'+str(int(dport))+'.pcap'\n",
    "        pcks = scapy.sendrecv.sniff(offline = file_path)\n",
    "        return pcks\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkls_dir ='../../../dataset/CICIDS2017/pkls'\n",
    "pkls_dir = './pkls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.join(pkls_dir, str(flow_class), str(index))).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['FTP-Patator', 'SSH-Patator', 'DoS slowloris','DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye', 'Heartbleed','Infiltration', 'Web Attack – Brute Force', 'Web Attack – XSS','Web Attack – Sql Injection', 'DDoS', 'PortScan', 'Bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {flow : i+1 for i, flow in enumerate(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FTP-Patator': 1,\n",
       " 'SSH-Patator': 2,\n",
       " 'DoS slowloris': 3,\n",
       " 'DoS Slowhttptest': 4,\n",
       " 'DoS Hulk': 5,\n",
       " 'DoS GoldenEye': 6,\n",
       " 'Heartbleed': 7,\n",
       " 'Infiltration': 8,\n",
       " 'Web Attack – Brute Force': 9,\n",
       " 'Web Attack – XSS': 10,\n",
       " 'Web Attack – Sql Injection': 11,\n",
       " 'DDoS': 12,\n",
       " 'PortScan': 13,\n",
       " 'Bot': 14}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = FlowSaver(10000,0,pkls_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/513564 [00:01<18:52:26,  7.56it/s]\n"
     ]
    }
   ],
   "source": [
    "normal.save_flow(pure_Benign_DF,Thu_pcap_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_file_allowed_extension(filename, extensions):\n",
    "    return filename.lower().endswith(extensions)\n",
    "\n",
    "def make_dataset(directory, class_to_idx, extensions='.pkl'):\n",
    "    instances = []\n",
    "    directory = os.path.expanduser(directory)\n",
    "    def is_valid_file(x):\n",
    "        return has_file_allowed_extension(x, extensions)\n",
    "    for target_class in sorted(class_to_idx.keys()):\n",
    "        class_index = class_to_idx[target_class]\n",
    "        target_dir = os.path.join(directory, target_class)\n",
    "        if not os.path.isdir(target_dir):\n",
    "            continue\n",
    "        for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "                if is_valid_file(path):\n",
    "                    item = path, class_index\n",
    "                    instances.append(item)\n",
    "    return instances\n",
    "\n",
    "class PklsFolder(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        classes, class_to_idx = self._find_classes(root_dir)\n",
    "        samples = make_dataset(root_dir, class_to_idx)\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in samples]\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        with open(path, 'rb') as f:\n",
    "            sample = pickle.load(f)\n",
    "        \"\"\"\n",
    "        flow = np.zeros([128, 1500])\n",
    "        for i in range(len(sample)):\n",
    "            flow[i, :len(sample[i])] = np.frombuffer(sample[i][:1500], dtype=np.uint8)\n",
    "            #randomize MAC,IP addresses\n",
    "            flow[i, 0:12] = np.random.randint(256, size = 12, dtype = np.uint8)\n",
    "            flow[i, 26:34] = np.random.randint(256, size = 8, dtype = np.uint8)\n",
    "        \"\"\"\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PklsFolder(pkls_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 08:59:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:00:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:01:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n",
      "2017-07-06 09:02:00\n"
     ]
    }
   ],
   "source": [
    "for pck in pcks:\n",
    "    print((datetime.fromtimestamp(pck.time) - timedelta(hours = 12)).replace(second = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "for five_tup in dup_Mal_DF.groupby(['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol']).groups.keys():\n",
    "    flows = dup_Mal_DF[(dup_Mal_DF['Source IP'] == five_tup[0]) & (dup_Mal_DF['Source Port'] == five_tup[1]) & (dup_Mal_DF['Destination IP'] == five_tup[2]) & (dup_Mal_DF['Destination Port'] == five_tup[3]) & (dup_Mal_DF['Protocol'] == five_tup[4])]\n",
    "    time = {flow[1]['Timestamp'] :  flow[1]['Label'] for flow in flows.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Label</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – Brute Force</td>\n",
       "      <td>6/7/2017 9:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>34940.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Web Attack – XSS</td>\n",
       "      <td>6/7/2017 10:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source IP  Source Port Destination IP  Destination Port  Protocol  \\\n",
       "712   172.16.0.1      34940.0  192.168.10.50              80.0       6.0   \n",
       "1961  172.16.0.1      34940.0  192.168.10.50              80.0       6.0   \n",
       "\n",
       "                         Label       Timestamp  \n",
       "712   Web Attack – Brute Force   6/7/2017 9:41  \n",
       "1961          Web Attack – XSS  6/7/2017 10:34  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_class_list = ['FTP-Patator', 'SSH-Patator', 'DoS slowloris','DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye', 'Heartbleed','Infiltration', 'Web Attack – Brute Force', 'Web Attack – XSS','Web Attack – Sql Injection', 'DDoS', 'PortScan', 'Bot']\n",
    "attack_class = {flow : i+1 for i, flow in enumerate(attack_class_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_pcap_dir = Thu_pcap_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "206\n",
      "2017-07-06 10:35:00\n",
      "2017-07-06 10:34:31\n",
      "total len : 210\n",
      "----------------------------------------------\n",
      "5\n",
      "4\n",
      "2017-07-06 10:18:00\n",
      "2017-07-06 10:17:05\n",
      "total len : 9\n",
      "----------------------------------------------\n",
      "4\n",
      "205\n",
      "2017-07-06 10:20:00\n",
      "2017-07-06 10:20:30\n",
      "total len : 209\n",
      "----------------------------------------------\n",
      "4\n",
      "205\n",
      "2017-07-06 10:22:00\n",
      "2017-07-06 10:21:34\n",
      "total len : 209\n",
      "----------------------------------------------\n",
      "5\n",
      "4\n",
      "2017-07-06 10:28:00\n",
      "2017-07-06 10:27:20\n",
      "total len : 9\n",
      "----------------------------------------------\n",
      "5\n",
      "4\n",
      "2017-07-06 10:29:00\n",
      "2017-07-06 10:28:05\n",
      "total len : 9\n",
      "----------------------------------------------\n",
      "2\n",
      "105\n",
      "2017-07-06 10:35:00\n",
      "2017-07-06 10:34:31\n",
      "total len : 107\n",
      "----------------------------------------------\n",
      "5\n",
      "2\n",
      "2017-07-06 10:18:00\n",
      "2017-07-06 10:17:05\n",
      "total len : 7\n",
      "----------------------------------------------\n",
      "3\n",
      "105\n",
      "2017-07-06 10:20:00\n",
      "2017-07-06 10:20:30\n",
      "total len : 108\n",
      "----------------------------------------------\n",
      "2\n",
      "105\n",
      "2017-07-06 10:22:00\n",
      "2017-07-06 10:21:34\n",
      "total len : 107\n",
      "----------------------------------------------\n",
      "5\n",
      "2\n",
      "2017-07-06 10:28:00\n",
      "2017-07-06 10:27:20\n",
      "total len : 7\n",
      "----------------------------------------------\n",
      "5\n",
      "2\n",
      "2017-07-06 10:29:00\n",
      "2017-07-06 10:28:05\n",
      "total len : 7\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not dup_Mal_DF.empty:\n",
    "    for _, flows in dup_Mal_DF.groupby(['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol']):\n",
    "        pcks = find_tup_pcap(flows.iloc[0], Day_pcap_dir)            \n",
    "        # Monday csv 파일만 flow를 초 단위로 구분\n",
    "        if Day_pcap_dir[-3:] == 'Mon':\n",
    "            time_label = {datetime.strptime(flow['Timestamp'],'%d/%m/%Y %H:%M:%S'): flow['Label'] for _, flow in flows.iterrows()}\n",
    "        else:\n",
    "            time_label = {datetime.strptime(flow['Timestamp'],'%d/%m/%Y %H:%M') : flow['Label'] for _, flow in flows.iterrows()}\n",
    "        \n",
    "        tmp = 0\n",
    "        for i in range(len(time_label)):\n",
    "            time, label = sorted(time_label.items())[i]\n",
    "            time_unit = timedelta(seconds =1) if Day_pcap_dir[-3:] == 'Mon' else timedelta(minutes= 1)  \n",
    "            time += time_unit\n",
    "            for p_idx in range(tmp,len(pcks)):\n",
    "                if ((datetime.fromtimestamp(pcks[p_idx].time) - timedelta(hours = 12)) >= time) or (p_idx == (len(pcks) -1)):\n",
    "                    flow_array = []\n",
    "                    if (p_idx == (len(pcks) -1)) or (i == len(time_label) -1):\n",
    "                        p_idx = len(pcks)\n",
    "                    for j in range(tmp,p_idx):\n",
    "                        flow_array.append(bytes(pcks[j]))\n",
    "                        attack[label].save_flow(flow_array)\n",
    "                    tmp = p_idx\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-06 09:41:45\n",
      "2017-07-06 09:41:45\n",
      "2017-07-06 09:41:51\n",
      "2017-07-06 09:41:51\n",
      "2017-07-06 10:33:22\n",
      "2017-07-06 10:33:22\n",
      "2017-07-06 10:33:27\n",
      "2017-07-06 10:33:27\n",
      "2017-07-06 10:33:27\n",
      "2017-07-06 10:33:27\n",
      "2017-07-06 10:33:28\n",
      "2017-07-06 10:33:28\n",
      "2017-07-06 10:33:28\n",
      "2017-07-06 10:33:28\n",
      "2017-07-06 10:33:29\n",
      "2017-07-06 10:33:29\n",
      "2017-07-06 10:33:30\n",
      "2017-07-06 10:33:30\n",
      "2017-07-06 10:33:31\n",
      "2017-07-06 10:33:31\n",
      "2017-07-06 10:33:31\n",
      "2017-07-06 10:33:31\n",
      "2017-07-06 10:33:32\n",
      "2017-07-06 10:33:32\n",
      "2017-07-06 10:33:32\n",
      "2017-07-06 10:33:32\n",
      "2017-07-06 10:33:33\n",
      "2017-07-06 10:33:33\n",
      "2017-07-06 10:33:33\n",
      "2017-07-06 10:33:33\n",
      "2017-07-06 10:33:35\n",
      "2017-07-06 10:33:35\n",
      "2017-07-06 10:33:35\n",
      "2017-07-06 10:33:35\n",
      "2017-07-06 10:33:36\n",
      "2017-07-06 10:33:36\n",
      "2017-07-06 10:33:36\n",
      "2017-07-06 10:33:36\n",
      "2017-07-06 10:33:37\n",
      "2017-07-06 10:33:37\n",
      "2017-07-06 10:33:37\n",
      "2017-07-06 10:33:37\n",
      "2017-07-06 10:33:38\n",
      "2017-07-06 10:33:38\n",
      "2017-07-06 10:33:39\n",
      "2017-07-06 10:33:39\n",
      "2017-07-06 10:33:40\n",
      "2017-07-06 10:33:40\n",
      "2017-07-06 10:33:40\n",
      "2017-07-06 10:33:40\n",
      "2017-07-06 10:33:41\n",
      "2017-07-06 10:33:41\n",
      "2017-07-06 10:33:41\n",
      "2017-07-06 10:33:41\n",
      "2017-07-06 10:33:42\n",
      "2017-07-06 10:33:42\n",
      "2017-07-06 10:33:42\n",
      "2017-07-06 10:33:42\n",
      "2017-07-06 10:33:43\n",
      "2017-07-06 10:33:43\n",
      "2017-07-06 10:33:44\n",
      "2017-07-06 10:33:44\n",
      "2017-07-06 10:33:44\n",
      "2017-07-06 10:33:45\n",
      "2017-07-06 10:33:45\n",
      "2017-07-06 10:33:45\n",
      "2017-07-06 10:33:45\n",
      "2017-07-06 10:33:46\n",
      "2017-07-06 10:33:46\n",
      "2017-07-06 10:33:46\n",
      "2017-07-06 10:33:46\n",
      "2017-07-06 10:33:47\n",
      "2017-07-06 10:33:47\n",
      "2017-07-06 10:33:48\n",
      "2017-07-06 10:33:48\n",
      "2017-07-06 10:33:49\n",
      "2017-07-06 10:33:49\n",
      "2017-07-06 10:33:49\n",
      "2017-07-06 10:33:49\n",
      "2017-07-06 10:33:50\n",
      "2017-07-06 10:33:50\n",
      "2017-07-06 10:33:50\n",
      "2017-07-06 10:33:50\n",
      "2017-07-06 10:33:51\n",
      "2017-07-06 10:33:51\n",
      "2017-07-06 10:33:51\n",
      "2017-07-06 10:33:52\n",
      "2017-07-06 10:33:53\n",
      "2017-07-06 10:33:53\n",
      "2017-07-06 10:33:53\n",
      "2017-07-06 10:33:53\n",
      "2017-07-06 10:33:54\n",
      "2017-07-06 10:33:54\n",
      "2017-07-06 10:33:54\n",
      "2017-07-06 10:33:54\n",
      "2017-07-06 10:33:55\n",
      "2017-07-06 10:33:55\n",
      "2017-07-06 10:33:55\n",
      "2017-07-06 10:33:55\n",
      "2017-07-06 10:33:56\n",
      "2017-07-06 10:33:56\n",
      "2017-07-06 10:33:57\n",
      "2017-07-06 10:33:57\n",
      "2017-07-06 10:33:58\n",
      "2017-07-06 10:33:58\n",
      "2017-07-06 10:33:58\n",
      "2017-07-06 10:33:58\n",
      "2017-07-06 10:33:59\n",
      "2017-07-06 10:33:59\n",
      "2017-07-06 10:33:59\n",
      "2017-07-06 10:33:59\n",
      "2017-07-06 10:34:00\n",
      "2017-07-06 10:34:00\n",
      "2017-07-06 10:34:01\n",
      "2017-07-06 10:34:01\n",
      "2017-07-06 10:34:02\n",
      "2017-07-06 10:34:02\n",
      "2017-07-06 10:34:02\n",
      "2017-07-06 10:34:02\n",
      "2017-07-06 10:34:03\n",
      "2017-07-06 10:34:03\n",
      "2017-07-06 10:34:03\n",
      "2017-07-06 10:34:03\n",
      "2017-07-06 10:34:04\n",
      "2017-07-06 10:34:04\n",
      "2017-07-06 10:34:04\n",
      "2017-07-06 10:34:04\n",
      "2017-07-06 10:34:05\n",
      "2017-07-06 10:34:05\n",
      "2017-07-06 10:34:06\n",
      "2017-07-06 10:34:06\n",
      "2017-07-06 10:34:07\n",
      "2017-07-06 10:34:07\n",
      "2017-07-06 10:34:07\n",
      "2017-07-06 10:34:07\n",
      "2017-07-06 10:34:08\n",
      "2017-07-06 10:34:08\n",
      "2017-07-06 10:34:08\n",
      "2017-07-06 10:34:08\n",
      "2017-07-06 10:34:09\n",
      "2017-07-06 10:34:09\n",
      "2017-07-06 10:34:10\n",
      "2017-07-06 10:34:10\n",
      "2017-07-06 10:34:11\n",
      "2017-07-06 10:34:11\n",
      "2017-07-06 10:34:11\n",
      "2017-07-06 10:34:11\n",
      "2017-07-06 10:34:12\n",
      "2017-07-06 10:34:12\n",
      "2017-07-06 10:34:12\n",
      "2017-07-06 10:34:12\n",
      "2017-07-06 10:34:13\n",
      "2017-07-06 10:34:13\n",
      "2017-07-06 10:34:13\n",
      "2017-07-06 10:34:13\n",
      "2017-07-06 10:34:14\n",
      "2017-07-06 10:34:14\n",
      "2017-07-06 10:34:15\n",
      "2017-07-06 10:34:15\n",
      "2017-07-06 10:34:16\n",
      "2017-07-06 10:34:16\n",
      "2017-07-06 10:34:16\n",
      "2017-07-06 10:34:16\n",
      "2017-07-06 10:34:17\n",
      "2017-07-06 10:34:17\n",
      "2017-07-06 10:34:17\n",
      "2017-07-06 10:34:17\n",
      "2017-07-06 10:34:18\n",
      "2017-07-06 10:34:18\n",
      "2017-07-06 10:34:19\n",
      "2017-07-06 10:34:19\n",
      "2017-07-06 10:34:20\n",
      "2017-07-06 10:34:20\n",
      "2017-07-06 10:34:20\n",
      "2017-07-06 10:34:20\n",
      "2017-07-06 10:34:21\n",
      "2017-07-06 10:34:21\n",
      "2017-07-06 10:34:21\n",
      "2017-07-06 10:34:21\n",
      "2017-07-06 10:34:22\n",
      "2017-07-06 10:34:22\n",
      "2017-07-06 10:34:22\n",
      "2017-07-06 10:34:22\n",
      "2017-07-06 10:34:23\n",
      "2017-07-06 10:34:23\n",
      "2017-07-06 10:34:24\n",
      "2017-07-06 10:34:24\n",
      "2017-07-06 10:34:25\n",
      "2017-07-06 10:34:25\n",
      "2017-07-06 10:34:25\n",
      "2017-07-06 10:34:25\n",
      "2017-07-06 10:34:26\n",
      "2017-07-06 10:34:26\n",
      "2017-07-06 10:34:26\n",
      "2017-07-06 10:34:26\n",
      "2017-07-06 10:34:27\n",
      "2017-07-06 10:34:27\n",
      "2017-07-06 10:34:28\n",
      "2017-07-06 10:34:28\n",
      "2017-07-06 10:34:29\n",
      "2017-07-06 10:34:29\n",
      "2017-07-06 10:34:29\n",
      "2017-07-06 10:34:29\n",
      "2017-07-06 10:34:30\n",
      "2017-07-06 10:34:30\n",
      "2017-07-06 10:34:30\n",
      "2017-07-06 10:34:30\n",
      "2017-07-06 10:34:31\n",
      "2017-07-06 10:34:31\n",
      "2017-07-06 10:34:31\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pcks)):\n",
    "    print(datetime.fromtimestamp(pcks[i].time) - timedelta(hours = 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import scapy.all\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(target):\n",
    "    return pd.read_csv(target,encoding='cp1252').rename(columns=lambda x: x.strip()).dropna(subset=['Flow ID'], how='all')\n",
    "\n",
    "def dataframe_from_csvs(targets):\n",
    "    return pd.concat([dataframe_from_csv(x) for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DtypeWarning: Columns (0,1,3,6,84) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "Thursday_csv= sorted([x for x in Path('../../../dataset/CICIDS2017/flow_label/TrafficLabelling').glob('Thursday-*.csv')],reverse = True)\n",
    "# Morning - Afternoon 순서로 정리하기 위해서\n",
    "\n",
    "Thursday_DF_RAW = dataframe_from_csvs(Thursday_csv)\n",
    "Thursday_DF = Thursday_DF_RAW.drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first')\n",
    "\n",
    "Day_DF = Thursday_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ben_mal_DF(Day_DF):\n",
    "    fwd_Benign_DF = Day_DF[Day_DF['Label'] == 'BENIGN'][['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Benign_DF = Day_DF[Day_DF['Label'] == 'BENIGN'][['Destination IP', 'Destination Port','Source IP', 'Source Port',  'Protocol','Label','Timestamp']]\n",
    "    bwd_Benign_DF.columns = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']\n",
    "    Benign_DF = pd.concat([fwd_Benign_DF, bwd_Benign_DF]).drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first').reset_index(drop = True)\n",
    "    \n",
    "    fwd_Mal_DF = Day_DF[Day_DF['Label'] != 'BENIGN'][['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Mal_DF = Day_DF[Day_DF['Label'] != 'BENIGN'][['Destination IP', 'Destination Port','Source IP', 'Source Port', 'Protocol','Label','Timestamp']]\n",
    "    bwd_Mal_DF.columns = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label','Timestamp']\n",
    "    Mal_DF = pd.concat([fwd_Mal_DF,bwd_Mal_DF]).drop_duplicates(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol','Label'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "    return Benign_DF, Mal_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Benign_DF ,Mal_DF = split_ben_mal_DF(Day_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mal_dup_list = Mal_DF.duplicated(subset = ['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol'],keep = False)    \n",
    "pure_Mal_DF = Mal_DF[~Mal_dup_list]\n",
    "dup_Mal_DF = Mal_DF[Mal_dup_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_Mal_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_Mal_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_dup_btw_df(df1, df2):\n",
    "    tmp = pd.concat([df1,df2]).reset_index(drop = True)\n",
    "    dup_index = tmp[tmp.duplicated(subset = ['Source IP','Source Port','Destination IP', 'Destination Port', 'Protocol'], keep = 'last')].index\n",
    "    dup_index = dup_index[dup_index < len(df1)]\n",
    "    return df1.drop(index = dup_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Benign flow에서 Mal flow와 5tup 같은 플로우 삭제\n",
    "pure_Benign_DF = del_dup_btw_df(Benign_DF,Mal_DF)\n",
    "\n",
    "#pure_Malicous flow-> Malicious flow로 라벨링\n",
    "#pure Benign flow -> Benign flow로 라벨링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tup_pcap(df, pcap_dir):\n",
    "    sip,sport,dip,dport,protocol = df[['Source IP','Source Port','Destination IP','Destination Port','Protocol']]\n",
    "    protocol = 'TCP' if int(protocol) ==6 else 'UDP' if int(protocol) ==17 else 'HOPOPT'\n",
    "    \n",
    "    if protocol == 'HOPOPT':\n",
    "        return False        \n",
    "    elif protocol == 'TCP' or five_tup[4] == 'UDP':\n",
    "        week = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "        file_path = pcap_dir + '/' + [day for day in week if pcap_dir[-3:] in day][0] +'-WorkingHours.pcap.'+protocol+'_'+sip.replace('.','-')+'_'+ str(int(sport))+'_'+dip.replace('.','-')+'_'+str(int(dport))+'.pcap'\n",
    "        #pcap 파일이 50MB 보다 크면 scapy 하는데 너무 오래 걸려서 그냥 버림 \n",
    "        if os.path.getsize(file_path) > 50000000:\n",
    "            return False\n",
    "        else:\n",
    "            return scapy.sendrecv.sniff(offline = file_path)\n",
    "    else :\n",
    "        print('Non-Exist Protocol')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tup_pcap(df, pcap_dir):\n",
    "    sip,sport,dip,dport,protocol = df[['Source IP','Source Port','Destination IP','Destination Port','Protocol']]\n",
    "    protocol = 'TCP' if int(protocol) ==6 else 'UDP' if int(protocol) ==17 else 'HOPOPT'\n",
    "    \n",
    "    if protocol == 'HOPOPT':\n",
    "        return False        \n",
    "    elif protocol == 'TCP' or five_tup[4] == 'UDP':\n",
    "        week = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "        file_path = pcap_dir + '/' + [day for day in week if pcap_dir[-3:] in day][0] +'-WorkingHours.pcap.'+protocol+'_'+sip.replace('.','-')+'_'+ str(int(sport))+'_'+dip.replace('.','-')+'_'+str(int(dport))+'.pcap'\n",
    "        #pcap 파일이 50MB 보다 크면 scapy 하는데 너무 오래 걸려서 그냥 버림 \n",
    "        if os.path.getsize(file_path) > 50000000:\n",
    "            return False\n",
    "        else:\n",
    "            return scapy.sendrecv.sniff(offline = file_path)\n",
    "    else :\n",
    "        print('Non-Exist Protocol')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thu_pcap_dir = '../../../dataset/CICIDS2017/split_pcaps/Thu'\n",
    "Day_pcap_dir = Thu_pcap_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 : 4]\n",
      "[4 : 210]\n",
      "[0 : 5]\n",
      "[5 : 9]\n",
      "[0 : 4]\n",
      "[4 : 209]\n",
      "[0 : 4]\n",
      "[4 : 209]\n",
      "[0 : 5]\n",
      "[5 : 9]\n",
      "[0 : 5]\n",
      "[5 : 9]\n",
      "[0 : 2]\n",
      "[2 : 107]\n",
      "[0 : 5]\n",
      "[5 : 7]\n",
      "[0 : 3]\n",
      "[3 : 108]\n",
      "[0 : 2]\n",
      "[2 : 107]\n",
      "[0 : 5]\n",
      "[5 : 7]\n",
      "[0 : 5]\n",
      "[5 : 7]\n"
     ]
    }
   ],
   "source": [
    "if not dup_Mal_DF.empty:\n",
    "    for _, flows in dup_Mal_DF.groupby(['Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol']):\n",
    "        pcks = find_tup_pcap(flows.iloc[0], Day_pcap_dir)            \n",
    "        # Monday csv 파일만 flow를 초 단위로 구분\n",
    "        if Day_pcap_dir[-3:] == 'Mon':\n",
    "            time_label = {datetime.strptime(flow['Timestamp'],'%d/%m/%Y %H:%M:%S'): flow['Label'] for _, flow in flows.iterrows()}\n",
    "        else:\n",
    "            time_label = {datetime.strptime(flow['Timestamp'],'%d/%m/%Y %H:%M') : flow['Label'] for _, flow in flows.iterrows()}\n",
    "\n",
    "        tmp = 0\n",
    "        for i in range(len(time_label)):\n",
    "            time, label = sorted(time_label.items())[i]\n",
    "            time_unit = timedelta(seconds =1) if Day_pcap_dir[-3:] == 'Mon' else timedelta(minutes=1)  \n",
    "            time += time_unit\n",
    "            for p_idx in range(tmp,len(pcks)):\n",
    "                if ((datetime.fromtimestamp(pcks[p_idx].time) - timedelta(hours = 12)) >= time) or (p_idx == (len(pcks) -1)):\n",
    "                    flow_array = []\n",
    "                    if (p_idx == (len(pcks) -1)) or (i == len(time_label) -1):\n",
    "                        p_idx = len(pcks)\n",
    "                    for j in range(tmp,p_idx):\n",
    "                        flow_array.append(bytes(pcks[j]))\n",
    "                    print(f'[{tmp} : {p_idx}]')\n",
    "                        #attack_saver[label].save_flow(flow_array)\n",
    "                    tmp = p_idx\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './hihi.txt'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.path.getsize('./hihi.txt')\n",
    "except OSError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOPOPT\n"
     ]
    }
   ],
   "source": [
    "protocol = 'TCP' if int(protocol) ==6 else 'UDP' if int(protocol) ==17 else 'HOPOPT'\n",
    "print(protocol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
